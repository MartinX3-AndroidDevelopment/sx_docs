---
title: "Kernel CI"
date: 2021-01-28T17:37:28+01:00
author: Felix
draft: true
---

With contributor time a scarce resource and images annoying to pass around in
our internal team, I decided to set up a [Continuous Integration][ci] system
that got immediate feedback on a pull request and bootable images into the hands
of testers.

For this article, I decided to go with [GitHub Actions][actions]; this is in now
way an endorsement of their offering - they're just very cheap.

### Requirements

At first, I decided to limit myself to the following:

- Run on every pull request targeting 4.14 (`LA.UM.7.1.r1` branch)
- Generate kernel images for all [devices supported on kernel 4.14][devices].
- Generate `dtbo.img` images for all devices with a separate `dtbo` partition.
- Make images available from web interface
- Full results available in less than 10min total

### Constraints

To achive those requirements, we need to know the parameters we are working
with.

GitHub's constraints are:

- [Runner parameters][params]:
  > - 2-core CPU
  > - 7 GB of RAM memory
  > - 14 GB of SSD disk space
- 20 [Concurrent jobs][jobs] available, 40 on "Pro" plan
- 90 days of [Artifact retention][retention]
- [Cache limits][cache-limits] & [Cache eviction][eviction]:
  > GitHub will remove any cache entries that have not been accessed in over 7
  > days. There is no limit on the number of caches you can store, but the total
  > size of all caches in a repository is limited to 5 GB. If you exceed this
  > limit, GitHub will save your cache but will begin **evicting caches until the
  > total size is less than 5 GB.**

Very important it the limitation of 5GB of cache space per repo, since the
kernel `out/` directory can already easily exceed **1.4GB**. This is not viable
for 20+ devices at once.

A **full rebuild** without any caches takes about **25 minutes** on a GitHub
runner, which would violate our requirement of 10 minutes or less in total.

### Challenge met

Let's see how we stacked up: A fast, parallelized build with intelligent caching
was required...

Gentlemen, we have met that objective, and then some.
Currently, a **partial (cached) rebuild across all devices takes about 3
minutes**, including upload of artifacts and cleanup.

How was this achieved? Mostly by utilizing caching (refreshed once a day),
careful selection of meaningful files, using git internals, shallow clones,
per-platform shared kernel `out/` directories and a bit of glue to hold
everything together.

### Short make detour

The kernel is built using the [make][make] build system. The top-level
`Makefile` pulls in sub-level `Makefiles`, sets up dependencies and build tools,
resolves configuration options using [Kconfig][kconfig] and a lot more.

Most interesting for us is the dependency resolution. In multi-stage build
processes, dependencies are built in order of requirement.
Say we have the following situation:

```
mylib.o: mylib.c  <--- input
	gcc -o mylib.o -c mylib.c

myprogram: myprogram.c mylib.o <---- intermediate
	gcc -shared -c myprogram.c mylib.o -o myprogram
```

The resolution is as follows: `myprogram` is the main output, called *target* in
make land, which relies on the input of `myprogram.c` and the *intermediate*
`mylib.o`. That intermediate object in turn is generated by the uppermost block
and it requires the input `mylib.c`.

```
# intermediate == target
#   |
#   v
mylib.o: mylib.c  <--- input
	gcc -o mylib.o -c mylib.c
#       ^
#       |
#  Rule for creating the target

# target     input   intermediate
#   |          |         |
#   v          v         v
myprogram: myprogram.c mylib.o
	gcc -shared -c myprogram.c mylib.o -o myprogram
```

If `mylib.c` is changed, `mylib.o` will also change, necessitating a rebuild of
`myprogram` as well. If, however, only `myprogram.c` is changed, only
`myprogram` will be rebuilt, but `mylib` will remain untouched.

The way `make` detects changes is by comparing timestamps - modification times
or `mtime`, to be exact. If any *input* or *intermediate* has been changed
**after** the last build of *target*, only the changed inputs and any *targets*
that rely on those changed inputs will be rebuilt.

In practice, most pull requests will only touch a small portion of kernel files,
say a Wi-Fi driver or maybe even just a small typo fix in a single file. In a
standard build environment, this would only trigger a *partial rebuild* which
should be a matter of maybe one to two minutes

### Git: Shallow waters are deadly

- actions/cache works by calling tar/untar, so timestamps are preserved. (posix
  archives, great)
- git itself does not store any timestamps
- we want to cut clone time and also resulting archive size, so set clone depth
  via depth=1
- hard-resetting from one shallow ref to another triggers a full checkout (since
  git has no common ancestor to work with) and thus timestamps are re-set to
  current time
- need to refresh index manually via calling git status
- git becomes aware of actual difference between ref on disk and ref to checkout
- only actually changed files are checked out, timestamps preservved
- kernel source and kernel out need to be kept in sync, kernel source newer than
  out spells disaster and triggers full rebuild

### Misc
Sadly, we do not have as cool a build farm as e.g. [ClangBuiltLinux][cbl] and
Linaro's `TuxSuite`.

It's insane that CI runners are tossed about like free candy. All those
resources, all those coal and nuclear plants running so that adult children can
play around with containers and feel like masters of the cloud.

M$ stamping out competitors via their war chest.

No direct access to hardware, makes debugging harder since all you do is wait
for CI, makes people less cautious, false sense of security with green checks
from CI instead of manually verifying.

### Calc

> let's see whether their machines can compress like my lappy does
> my back-of-the-envelope calculations say with 196MB per platform we can do 4 kernel revisions at once
> problem is just that more-frequently-used (in practice, the newer) kernel revisions will evict the caches of say 4.4 or 4.9
> because their caches will be saved more often
> and you cannot manually invalidate a cache
> Max Github Actions cache size: 1024MB * 5
> <strike>5120รท196 = 26,122</strike> (platforms in cache at once)
> 5120รท155 = 33 (platforms in cache at once)
> <strike>33รท6 = 4,353 </strike> (divided by 6 platforms per kernel revision)
> 33รท6 (divided by 6 platforms per kernel revision) = 5.5
> Minus <strike>393MB</strike> 343MB for shared kernel dir per kernel revision

So we gotta get the kernel source dir down as well...

So:
```
y = Possible concurrent kernel revisions
y = (5120 - (343 * x)) * 1/155 * 1/6
Where x is concurrent number of kernel revisions in cache
With x = 4
Storage = 4 * (343 + (155*6)) = 5092MB
```

```
Run actions/cache@v2
/usr/bin/docker exec  07727f2289b8ce65187dd0cacebf10d47c8e4d8063e73d29dea443987d139e01 sh -c "cat /etc/*release | grep ^ID"
Received 155189248 of 412061920 (37.7%), 147.9 MBs/sec
Received 343932928 of 412061920 (83.5%), 163.6 MBs/sec
Received 412061920 of 412061920 (100.0%), 145.5 MBs/sec
Cache Size: ~393 MB (412061920 B)
/usr/bin/tar -z -xf /__w/_temp/b4fe8dda-72e7-468c-9773-b6e4688f2079/cache.tgz -P -C /__w/kernel-sony/kernel-sony
Cache restored from key: kernel-sources-4.14-2021-01-31
```

```
Run actions/cache@v2
/usr/bin/docker exec  07727f2289b8ce65187dd0cacebf10d47c8e4d8063e73d29dea443987d139e01 sh -c "cat /etc/*release | grep ^ID"
Received 158830905 of 163025209 (97.4%), 151.3 MBs/sec
Received 163025209 of 163025209 (100.0%), 131.5 MBs/sec
Cache Size: ~155 MB (163025209 B)
/usr/bin/tar -z -xf /__w/_temp/2f02442c-cb1a-4c5f-ad9b-790493277bab/cache.tgz -P -C /__w/kernel-sony/kernel-sony
Cache restored from key: kernel-tmp-tar-br-4.14-kumano-2021-01-31
```

[actions]: https://github.com/features/actions
[ci]: https://en.wikipedia.org/wiki/Continuous_integration
[cbl]: https://github.com/ClangBuiltLinux/continuous-integration2
[devices]: {{< ref "sony-devices.md" >}}
[cache-limits]: https://github.com/actions/cache#cache-limits
[docs-caching]: https://docs.github.com/en/actions/guides/caching-dependencies-to-speed-up-workflows
[eviction]: https://docs.github.com/en/actions/guides/caching-dependencies-to-speed-up-workflows#usage-limits-and-eviction-policy
[jobs]: https://docs.github.com/en/actions/reference/usage-limits-billing-and-administration#usage-limits
[retention]: https://docs.github.com/en/actions/reference/usage-limits-billing-and-administration#artifact-and-log-retention-policy
[params]: https://docs.github.com/en/actions/reference/specifications-for-github-hosted-runners#supported-runners-and-hardware-resources
[make]: https://en.wikipedia.org/wiki/Make_(software)
[kconfig]: https://www.kernel.org/doc/html/latest/kbuild/kconfig-language.html
[minimal]: {{< ref "2021-01-28-minimal-kernel-container.md" >}}
